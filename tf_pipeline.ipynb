{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 13:13:44.679243: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39msys\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m PCA\n",
      "File \u001b[0;32m/opt/miniconda3/envs/algonauts/lib/python3.10/site-packages/tensorflow/__init__.py:37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/algonauts/lib/python3.10/site-packages/tensorflow/python/__init__.py:36\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtraceback\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/algonauts/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py:62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pywrap_tensorflow_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     63\u001b[0m \u001b[39m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[39m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr as corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context manager to suppress stdout\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose where to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'jupyter_notebook' #@param ['colab', 'jupyter_notebook'] {allow-input: true}\n",
    "\n",
    "if platform == 'colab':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/', force_remount=True)\n",
    "    data_dir = '/content/drive/MyDrive/algonauts_2023_tutorial_data' #@param {type:\"string\"}\n",
    "    parent_submission_dir = '/content/drive/MyDrive/algonauts_2023_challenge_submission' #@param {type:\"string\"}\n",
    "\n",
    "if platform == 'jupyter_notebook':\n",
    "    data_dir = './algonauts_2023_challenge_data'\n",
    "    parent_submission_dir = './algonauts_2023_challenge_submission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_correlation(lh_correlation, rh_correlation, data_dir):\n",
    "    # Load the ROI classes mapping dictionaries\n",
    "    roi_mapping_files = ['mapping_prf-visualrois.npy', 'mapping_floc-bodies.npy',\n",
    "        'mapping_floc-faces.npy', 'mapping_floc-places.npy',\n",
    "        'mapping_floc-words.npy', 'mapping_streams.npy']\n",
    "    roi_name_maps = []\n",
    "    for r in roi_mapping_files:\n",
    "        roi_name_maps.append(np.load(os.path.join(data_dir, 'roi_masks', r),\n",
    "            allow_pickle=True).item())\n",
    "\n",
    "    # Load the ROI brain surface maps\n",
    "    lh_challenge_roi_files = ['lh.prf-visualrois_challenge_space.npy',\n",
    "        'lh.floc-bodies_challenge_space.npy', 'lh.floc-faces_challenge_space.npy',\n",
    "        'lh.floc-places_challenge_space.npy', 'lh.floc-words_challenge_space.npy',\n",
    "        'lh.streams_challenge_space.npy']\n",
    "    rh_challenge_roi_files = ['rh.prf-visualrois_challenge_space.npy',\n",
    "        'rh.floc-bodies_challenge_space.npy', 'rh.floc-faces_challenge_space.npy',\n",
    "        'rh.floc-places_challenge_space.npy', 'rh.floc-words_challenge_space.npy',\n",
    "        'rh.streams_challenge_space.npy']\n",
    "    lh_challenge_rois = []\n",
    "    rh_challenge_rois = []\n",
    "    for r in range(len(lh_challenge_roi_files)):\n",
    "        lh_challenge_rois.append(np.load(os.path.join(data_dir, 'roi_masks',\n",
    "            lh_challenge_roi_files[r])))\n",
    "        rh_challenge_rois.append(np.load(os.path.join(data_dir, 'roi_masks',\n",
    "            rh_challenge_roi_files[r])))\n",
    "\n",
    "    # Select the correlation results vertices of each ROI\n",
    "    roi_names = []\n",
    "    lh_roi_correlation = []\n",
    "    rh_roi_correlation = []\n",
    "    for r1 in range(len(lh_challenge_rois)):\n",
    "        for r2 in roi_name_maps[r1].items():\n",
    "            if r2[0] != 0: # zeros indicate to vertices falling outside the ROI of interest\n",
    "                roi_names.append(r2[1])\n",
    "                lh_roi_idx = np.where(lh_challenge_rois[r1] == r2[0])[0]\n",
    "                rh_roi_idx = np.where(rh_challenge_rois[r1] == r2[0])[0]\n",
    "                lh_roi_correlation.append(lh_correlation[lh_roi_idx])\n",
    "                rh_roi_correlation.append(rh_correlation[rh_roi_idx])\n",
    "    roi_names.append('All vertices')\n",
    "    lh_roi_correlation.append(lh_correlation)\n",
    "    rh_roi_correlation.append(rh_correlation)\n",
    "\n",
    "    # Create the plot\n",
    "    lh_median_roi_correlation = [np.median(lh_roi_correlation[r])\n",
    "        for r in range(len(lh_roi_correlation))]\n",
    "    rh_median_roi_correlation = [np.median(rh_roi_correlation[r])\n",
    "        for r in range(len(rh_roi_correlation))]\n",
    "    plt.figure(figsize=(18,6))\n",
    "    x = np.arange(len(roi_names))\n",
    "    width = 0.30\n",
    "    plt.bar(x - width/2, lh_median_roi_correlation, width, label='Left Hemisphere')\n",
    "    plt.bar(x + width/2, rh_median_roi_correlation, width,\n",
    "        label='Right Hemishpere')\n",
    "    plt.xlim(left=min(x)-.5, right=max(x)+.5)\n",
    "    plt.ylim(bottom=0, top=1)\n",
    "    plt.xlabel('ROIs')\n",
    "    plt.xticks(ticks=x, labels=roi_names, rotation=60)\n",
    "    plt.ylabel('Median Pearson\\'s $r$')\n",
    "    plt.legend(frameon=True, loc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calulate_correlaction(lh_fmri_val, lh_fmri_val_pred, rh_fmri_val, rh_fmri_val_pred):\n",
    "    # Empty correlation array of shape: (LH vertices)\n",
    "    lh_correlation = np.zeros(lh_fmri_val_pred.shape[1])\n",
    "    # Correlate each predicted LH vertex with the corresponding ground truth vertex\n",
    "    for v in range(lh_fmri_val_pred.shape[1]):\n",
    "        lh_correlation[v] = corr(lh_fmri_val_pred[:,v], lh_fmri_val[:,v])[0]\n",
    "\n",
    "    # Empty correlation array of shape: (RH vertices)\n",
    "    rh_correlation = np.zeros(rh_fmri_val_pred.shape[1])\n",
    "    # Correlate each predicted RH vertex with the corresponding ground truth vertex\n",
    "    for v in range(rh_fmri_val_pred.shape[1]):\n",
    "        rh_correlation[v] = corr(rh_fmri_val_pred[:,v], rh_fmri_val[:,v])[0]\n",
    "    return lh_correlation, rh_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(lh_fmri_test_pred, rh_fmri_test_pred, subject_submission_dir):\n",
    "    lh_fmri_test_pred = lh_fmri_test_pred.astype(np.float32)\n",
    "    rh_fmri_test_pred = rh_fmri_test_pred.astype(np.float32)\n",
    "\n",
    "    np.save(os.path.join(subject_submission_dir, 'lh_pred_test.npy'), lh_fmri_test_pred)\n",
    "    np.save(os.path.join(subject_submission_dir, 'rh_pred_test.npy'), rh_fmri_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fmri data and image datasets per subject\n",
    "def load_FMRI_and_images(subj_dir, create_dataset_from_image_paths):\n",
    "    train_img_dir  = os.path.join(subj_dir, 'training_split', 'training_images')\n",
    "    test_img_dir  = os.path.join(subj_dir, 'test_split', 'test_images')\n",
    "    train_img_list = os.listdir(train_img_dir)\n",
    "    # Create a dataset\n",
    "    batch_size = 300\n",
    "    split = 0.9\n",
    "    num_batches_train = int(len(train_img_list) * split // batch_size)\n",
    "    num_samples_train = int(num_batches_train * batch_size)\n",
    "    # Handle frmi files\n",
    "    fmri_dir = os.path.join(subj_dir, 'training_split', 'training_fmri')\n",
    "    lh_fmri = np.load(os.path.join(fmri_dir, 'lh_training_fmri.npy'))\n",
    "    rh_fmri = np.load(os.path.join(fmri_dir, 'rh_training_fmri.npy'))\n",
    "\n",
    "    print('LH training fMRI data shape:')\n",
    "    print(lh_fmri.shape)\n",
    "    print('(Training stimulus images × LH vertices)')\n",
    "\n",
    "    print('\\nRH training fMRI data shape:')\n",
    "    print(rh_fmri.shape)\n",
    "    print('(Training stimulus images × RH vertices)')\n",
    "    lh_fmri_train = lh_fmri[:num_samples_train]\n",
    "    lh_fmri_val = lh_fmri[num_samples_train:]\n",
    "    rh_fmri_train = rh_fmri[:num_samples_train]\n",
    "    rh_fmri_val = rh_fmri[num_samples_train:]\n",
    "\n",
    "    dataset = create_dataset_from_image_paths(train_img_dir)\n",
    "    # create train and validation dataset from the training dataset (90% train, 10% validation)\n",
    "    train_dataset = dataset.take(num_batches_train)\n",
    "    val_dataset = dataset.skip(num_batches_train)\n",
    "\n",
    "    test_dataset = create_dataset_from_image_paths(test_img_dir)\n",
    "\n",
    "    print('Training dataset size: ' + str(len(train_dataset)))\n",
    "    print('Validation dataset size: ' + str(len(val_dataset)))\n",
    "    print('Test dataset size: ' + str(len(test_dataset)) + '\\n')\n",
    "\n",
    "    return (train_dataset, val_dataset, test_dataset, lh_fmri_train, lh_fmri_val, rh_fmri_train, rh_fmri_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(subj_dir, readout_layer, base_model, lh_fmri_train, rh_fmri_train, lh_fmri_val, rh_fmri_val, train_dataset, val_dataset, test_dataset):\n",
    "    \n",
    "    model = tf.keras.Model(inputs=base_model.input, outputs=base_model.get_layer(readout_layer).output)\n",
    "    pca = PCA(n_components=100)\n",
    "\n",
    "    # Fit PCA to batch of datastet\n",
    "    for batch in train_dataset:\n",
    "        with HiddenPrints():\n",
    "            # Extract features\n",
    "            features = model.predict(batch)\n",
    "            # Flatten the features\n",
    "            features = features.reshape(features.shape[0], -1)\n",
    "            # Fit PCA to batch of features\n",
    "            pca.fit(features)\n",
    "\n",
    "    # print('plot the explained variance')\n",
    "    # plt.plot(pca.explained_variance_ratio_)\n",
    "    # plt.show()\n",
    "    # print('plot the cumulative explained variance')\n",
    "    # plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    # plt.show()\n",
    "\n",
    "    def extract_features(dataset, model, pca):\n",
    "        features = []\n",
    "        for batch in dataset:\n",
    "            with HiddenPrints():\n",
    "                ft = model.predict(batch)\n",
    "                # Flatten the features\n",
    "                ft = ft.reshape(ft.shape[0], -1)\n",
    "                # Fit PCA to batch of features\n",
    "                ft = pca.transform(ft)\n",
    "            features.append(ft)\n",
    "        return np.vstack(features)\n",
    "\n",
    "    features_train = extract_features(train_dataset, model, pca)\n",
    "    features_val = extract_features(val_dataset, model, pca)\n",
    "    features_test = extract_features(test_dataset, model, pca)\n",
    "\n",
    "    del model, pca\n",
    "    # Fitting regression\n",
    "    reg_lh = LinearRegression().fit(features_train, lh_fmri_train)\n",
    "    reg_rh = LinearRegression().fit(features_train, rh_fmri_train)\n",
    "    # Use fitted linear regressions to predict the validation and test fMRI data\n",
    "    lh_fmri_val_pred = reg_lh.predict(features_val)\n",
    "    lh_fmri_test_pred = reg_lh.predict(features_test)\n",
    "    rh_fmri_val_pred = reg_rh.predict(features_val)\n",
    "    rh_fmri_test_pred = reg_rh.predict(features_test)\n",
    "    # Calculate correlation\n",
    "    lh_correlation, rh_correlation = calulate_correlaction(lh_fmri_val, lh_fmri_val_pred, rh_fmri_val, rh_fmri_val_pred)\n",
    "    print('Left hemisphere median correlation: ', np.median(lh_correlation))\n",
    "    print('Right hemisphere median correlation: ', np.median(rh_correlation))\n",
    "    # Visualize\n",
    "    visualize_correlation(lh_correlation, rh_correlation, subj_dir)\n",
    "    return (lh_fmri_test_pred, rh_fmri_test_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify image preprocessing steps, model and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_from_image_paths(image_dir):\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(image_dir, image_size=(300, 300), labels=None, shuffle=False, batch_size=batch_size)\n",
    "    dataset = dataset.map(tf.keras.applications.efficientnet.preprocess_input)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Take models from here https://keras.io/api/applications/\n",
    "base_model = tf.keras.applications.EfficientNetB3(weights='imagenet')\n",
    "for layer in base_model.layers:\n",
    "    print(layer.name, end=' -> ')\n",
    "\n",
    "layers = ['block5d_bn', 'block5c_bn', 'block5b_bn', 'block5a_bn']\n",
    "# layers = ['block4e_bn', 'block3c_bn', 'block2c_bn', 'block1b_bn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = 'subj01'\n",
    "subj_dir = os.path.join(data_dir, subj)\n",
    "train_dataset, val_dataset, test_dataset, lh_fmri_train, lh_fmri_val, rh_fmri_train, rh_fmri_val = load_FMRI_and_images(subj_dir, create_dataset_from_image_paths)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for readout_layer in layers:\n",
    "    print(f'Readout layer: {readout_layer}\\n')\n",
    "    lh_fmri_test_pred, rh_fmri_test_pred = run_pipeline(subj_dir, readout_layer, base_model, lh_fmri_train, rh_fmri_train, lh_fmri_val, rh_fmri_val, train_dataset, val_dataset, test_dataset)\n",
    "    save_predictions(lh_fmri_test_pred, rh_fmri_test_pred, os.path.join(parent_submission_dir, subj_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "365c028d1c840c93b0f470009ef966704a741407ca08d29f5bd0c0c6373757cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
