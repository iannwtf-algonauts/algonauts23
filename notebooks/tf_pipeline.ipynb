{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context manager to suppress stdoutm for annoying long printouts\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'tf_resnet50'\n",
    "batch_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'paperspace' #@param ['colab', 'paperspace'] {allow-input: true}\n",
    "\n",
    "if platform == 'jupyter_notebook':\n",
    "    challenge_data_dir = '../data/algonauts_2023_challenge_data'\n",
    "    exp_output_dir = f'../data/out/{experiment}'\n",
    "\n",
    "if platform == 'paperspace':\n",
    "    challenge_data_dir = '/storage/algonauts_2023_challenge_data'\n",
    "    exp_output_dir = f'../data/out/{experiment}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions not aligned with the current structuree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pca(model, train_dataset):\n",
    "    \n",
    "    features = []\n",
    "    for batch in train_dataset:\n",
    "        # Extract features\n",
    "        with HiddenPrints():\n",
    "            ft = model.predict(batch)\n",
    "        # Flatten the features\n",
    "        ft = ft.reshape(ft.shape[0], -1)\n",
    "        # Append to list\n",
    "        features.append(ft)\n",
    "    # Combine features from all batches\n",
    "    features = np.vstack(features)\n",
    "\n",
    "    # Fit PCA to combined features\n",
    "    pca = PCA(n_components=100)\n",
    "    print('PCA fitting...')\n",
    "    pca.fit(features)\n",
    "    print('PCA over')\n",
    "    # print('plot the explained variance')\n",
    "    # plt.plot(pca.explained_variance_ratio_)\n",
    "    # plt.show()\n",
    "    # print('plot the cumulative explained variance')\n",
    "    # plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    # plt.show()\n",
    "    return pca\n",
    "\n",
    "def extract_and_transform_features(dataset, model, pca):\n",
    "    features = []\n",
    "    for batch in dataset:\n",
    "        with HiddenPrints():\n",
    "            ft = model.predict(batch)\n",
    "        # Flatten the features\n",
    "        ft = ft.reshape(ft.shape[0], -1)\n",
    "        # Fit PCA to batch of features\n",
    "        ft = pca.transform(ft)\n",
    "        features.append(ft)\n",
    "    return np.vstack(features)\n",
    "\n",
    "def load_datasets(dataset, image_size, normalise_dataset):\n",
    "    train_val_imgs_paths = [os.path.join(dataset.train_img_dir, img_name) for img_name in dataset.training_img_list]\n",
    "    train_paths = [train_val_imgs_paths[i] for i in dataset.idxs_train]\n",
    "    val_paths = [train_val_imgs_paths[i] for i in dataset.idxs_val]\n",
    "    test_imgs_paths = [os.path.join(dataset.test_img_dir, img_name) for img_name in dataset.test_img_list]\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices(val_paths)\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices(test_imgs_paths)\n",
    "\n",
    "    def load_image(image_path):\n",
    "        # load image file\n",
    "        img = tf.io.read_file(image_path)\n",
    "        # decode image\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        # resize image to a fixed shape\n",
    "        img = tf.image.resize(img, image_size)\n",
    "        return img\n",
    "    \n",
    "    def process(ds):\n",
    "        ds = ds.map(load_image)\n",
    "        ds = ds.map(normalise_dataset)\n",
    "        ds = ds.batch(batch_size)\n",
    "        ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "        return ds\n",
    "    \n",
    "    train_ds = process(train_ds)\n",
    "    val_ds = process(val_ds)\n",
    "    test_ds = process(test_ds)\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "def save_predictions(lh_fmri_test_pred, rh_fmri_test_pred, subject_submission_dir):\n",
    "    lh_fmri_test_pred = lh_fmri_test_pred.astype(np.float32)\n",
    "    rh_fmri_test_pred = rh_fmri_test_pred.astype(np.float32)\n",
    "\n",
    "    np.save(os.path.join(subject_submission_dir, 'lh_pred_test.npy'), lh_fmri_test_pred)\n",
    "    np.save(os.path.join(subject_submission_dir, 'rh_pred_test.npy'), rh_fmri_test_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify model and appropriate image preprocessing steps\n",
    "Define a function to load and return the model, printing its layers.\n",
    "Due to memory constraints, we will delete the model from memory in each loop. Here we first load it, print its\n",
    "nodes and delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_5 -> conv1_pad -> conv1_conv -> conv1_bn -> conv1_relu -> pool1_pad -> pool1_pool -> conv2_block1_1_conv -> conv2_block1_1_bn -> conv2_block1_1_relu -> conv2_block1_2_conv -> conv2_block1_2_bn -> conv2_block1_2_relu -> conv2_block1_0_conv -> conv2_block1_3_conv -> conv2_block1_0_bn -> conv2_block1_3_bn -> conv2_block1_add -> conv2_block1_out -> conv2_block2_1_conv -> conv2_block2_1_bn -> conv2_block2_1_relu -> conv2_block2_2_conv -> conv2_block2_2_bn -> conv2_block2_2_relu -> conv2_block2_3_conv -> conv2_block2_3_bn -> conv2_block2_add -> conv2_block2_out -> conv2_block3_1_conv -> conv2_block3_1_bn -> conv2_block3_1_relu -> conv2_block3_2_conv -> conv2_block3_2_bn -> conv2_block3_2_relu -> conv2_block3_3_conv -> conv2_block3_3_bn -> conv2_block3_add -> conv2_block3_out -> conv3_block1_1_conv -> conv3_block1_1_bn -> conv3_block1_1_relu -> conv3_block1_2_conv -> conv3_block1_2_bn -> conv3_block1_2_relu -> conv3_block1_0_conv -> conv3_block1_3_conv -> conv3_block1_0_bn -> conv3_block1_3_bn -> conv3_block1_add -> conv3_block1_out -> conv3_block2_1_conv -> conv3_block2_1_bn -> conv3_block2_1_relu -> conv3_block2_2_conv -> conv3_block2_2_bn -> conv3_block2_2_relu -> conv3_block2_3_conv -> conv3_block2_3_bn -> conv3_block2_add -> conv3_block2_out -> conv3_block3_1_conv -> conv3_block3_1_bn -> conv3_block3_1_relu -> conv3_block3_2_conv -> conv3_block3_2_bn -> conv3_block3_2_relu -> conv3_block3_3_conv -> conv3_block3_3_bn -> conv3_block3_add -> conv3_block3_out -> conv3_block4_1_conv -> conv3_block4_1_bn -> conv3_block4_1_relu -> conv3_block4_2_conv -> conv3_block4_2_bn -> conv3_block4_2_relu -> conv3_block4_3_conv -> conv3_block4_3_bn -> conv3_block4_add -> conv3_block4_out -> conv4_block1_1_conv -> conv4_block1_1_bn -> conv4_block1_1_relu -> conv4_block1_2_conv -> conv4_block1_2_bn -> conv4_block1_2_relu -> conv4_block1_0_conv -> conv4_block1_3_conv -> conv4_block1_0_bn -> conv4_block1_3_bn -> conv4_block1_add -> conv4_block1_out -> conv4_block2_1_conv -> conv4_block2_1_bn -> conv4_block2_1_relu -> conv4_block2_2_conv -> conv4_block2_2_bn -> conv4_block2_2_relu -> conv4_block2_3_conv -> conv4_block2_3_bn -> conv4_block2_add -> conv4_block2_out -> conv4_block3_1_conv -> conv4_block3_1_bn -> conv4_block3_1_relu -> conv4_block3_2_conv -> conv4_block3_2_bn -> conv4_block3_2_relu -> conv4_block3_3_conv -> conv4_block3_3_bn -> conv4_block3_add -> conv4_block3_out -> conv4_block4_1_conv -> conv4_block4_1_bn -> conv4_block4_1_relu -> conv4_block4_2_conv -> conv4_block4_2_bn -> conv4_block4_2_relu -> conv4_block4_3_conv -> conv4_block4_3_bn -> conv4_block4_add -> conv4_block4_out -> conv4_block5_1_conv -> conv4_block5_1_bn -> conv4_block5_1_relu -> conv4_block5_2_conv -> conv4_block5_2_bn -> conv4_block5_2_relu -> conv4_block5_3_conv -> conv4_block5_3_bn -> conv4_block5_add -> conv4_block5_out -> conv4_block6_1_conv -> conv4_block6_1_bn -> conv4_block6_1_relu -> conv4_block6_2_conv -> conv4_block6_2_bn -> conv4_block6_2_relu -> conv4_block6_3_conv -> conv4_block6_3_bn -> conv4_block6_add -> conv4_block6_out -> conv5_block1_1_conv -> conv5_block1_1_bn -> conv5_block1_1_relu -> conv5_block1_2_conv -> conv5_block1_2_bn -> conv5_block1_2_relu -> conv5_block1_0_conv -> conv5_block1_3_conv -> conv5_block1_0_bn -> conv5_block1_3_bn -> conv5_block1_add -> conv5_block1_out -> conv5_block2_1_conv -> conv5_block2_1_bn -> conv5_block2_1_relu -> conv5_block2_2_conv -> conv5_block2_2_bn -> conv5_block2_2_relu -> conv5_block2_3_conv -> conv5_block2_3_bn -> conv5_block2_add -> conv5_block2_out -> conv5_block3_1_conv -> conv5_block3_1_bn -> conv5_block3_1_relu -> conv5_block3_2_conv -> conv5_block3_2_bn -> conv5_block3_2_relu -> conv5_block3_3_conv -> conv5_block3_3_bn -> conv5_block3_add -> conv5_block3_out -> avg_pool -> predictions\n"
     ]
    }
   ],
   "source": [
    "def load_model():\n",
    "    # Take models from here https://keras.io/api/applications/\n",
    "    model = tf.keras.applications.ResNet50(weights='imagenet')\n",
    "    return model\n",
    "\n",
    "normalise_dataset = tf.keras.applications.resnet50.preprocess_input\n",
    "image_size = (224, 224)\n",
    "\n",
    "model = load_model()\n",
    "print(*(layer.name for layer in model.layers), sep=' -> ')\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select layers and subjects\n",
    "Now let's define which layer(s) we will pick from, and which subject(s) to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = ['conv5_block2_out']\n",
    "subjects = [1] #, 2, 3, 4, 5, 6, 7, 8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for layer conv5_block2_out\n",
      "Running for subject 1\n",
      "Training images: 9841\n",
      "Test images: 159\n",
      "LH training fMRI data shape:\n",
      "(9841, 19004)\n",
      "(Training stimulus images × LH vertices)\n",
      "\n",
      "RH training fMRI data shape:\n",
      "(9841, 20544)\n",
      "(Training stimulus images × RH vertices)\n",
      "Training images: 9841\n",
      "Test images: 159\n",
      "Training stimulus images: 8856\n",
      "\n",
      "Validation stimulus images: 985\n",
      "\n",
      "Test stimulus images: 159\n"
     ]
    }
   ],
   "source": [
    "from src.algonauts.evaluators import correlations as corr\n",
    "from src.algonauts.data_processors.nsd_dataset import NSDDataset\n",
    "\n",
    "for layer_name in layers:\n",
    "    print(f'Running for layer {layer_name}')\n",
    "    for subj in subjects:\n",
    "        print(f'Running for subject {subj}')\n",
    "\n",
    "        # Set data directories based on parameters\n",
    "        output_dir = f'{exp_output_dir}/{layer_name}'\n",
    "        dataset = NSDDataset(challenge_data_dir, output_dir, subj)\n",
    "\n",
    "        train_ds, val_ds, test_ds = load_datasets(dataset, image_size, normalise_dataset)\n",
    "        \n",
    "        # Load model for the iteration\n",
    "        model = load_model()\n",
    "        sliced_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "        # Train PCA\n",
    "        pca = train_pca(sliced_model, train_ds)\n",
    "\n",
    "        # Extract and transform features\n",
    "        train_features = extract_and_transform_features(train_ds, sliced_model, pca)\n",
    "        val_features = extract_and_transform_features(val_ds, sliced_model, pca)\n",
    "        test_features = extract_and_transform_features(test_ds, sliced_model, pca)\n",
    "\n",
    "        # Delete model to free up memory\n",
    "        del model, pca\n",
    "\n",
    "        # Fit regression\n",
    "        reg_lh = LinearRegression().fit(train_features, dataset.lh_fmri_train)\n",
    "        reg_rh = LinearRegression().fit(train_features, dataset.rh_fmri_train)\n",
    "        \n",
    "        # Use fitted linear regressions to predict the validation and test fMRI data\n",
    "        lh_fmri_val_pred = reg_lh.predict(val_features)\n",
    "        lh_fmri_test_pred = reg_lh.predict(test_features)\n",
    "        rh_fmri_val_pred = reg_rh.predict(val_features)\n",
    "        rh_fmri_test_pred = reg_rh.predict(test_features)\n",
    "        # Calculate correlations for each hemispher\n",
    "        lh_correlation = corr.calculate_correlation(lh_fmri_val_pred, dataset.lh_fmri_val)\n",
    "        rh_correlation = corr.calculate_correlation(rh_fmri_val_pred, dataset.rh_fmri_val)  \n",
    "    \n",
    "        corr.plot_and_write_correlations(dataset, lh_correlation, rh_correlation, exp_output_dir, layer_name, subj)\n",
    "        save_predictions(lh_fmri_test_pred, rh_fmri_test_pred, dataset.subject_submission_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "365c028d1c840c93b0f470009ef966704a741407ca08d29f5bd0c0c6373757cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
