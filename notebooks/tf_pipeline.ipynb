{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.decomposition import IncrementalPCA, PCA\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr as corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context manager to suppress stdout\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose where to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'jupyter_notebook' #@param ['colab', 'jupyter_notebook'] {allow-input: true}\n",
    "\n",
    "if platform == 'colab':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/', force_remount=True)\n",
    "    data_dir = '/content/drive/MyDrive/algonauts_2023_tutorial_data' #@param {type:\"string\"}\n",
    "    submission_dir = '/content/drive/MyDrive/algonauts_2023_challenge_submission' #@param {type:\"string\"}\n",
    "\n",
    "if platform == 'jupyter_notebook':\n",
    "    data_dir = './algonauts_2023_challenge_data'\n",
    "    submission_dir = './algonauts_2023_challenge_submission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_correlation(lh_correlation, rh_correlation, data_dir):\n",
    "    # Load the ROI classes mapping dictionaries\n",
    "    roi_mapping_files = ['mapping_prf-visualrois.npy', 'mapping_floc-bodies.npy',\n",
    "        'mapping_floc-faces.npy', 'mapping_floc-places.npy',\n",
    "        'mapping_floc-words.npy', 'mapping_streams.npy']\n",
    "    roi_name_maps = []\n",
    "    for r in roi_mapping_files:\n",
    "        roi_name_maps.append(np.load(os.path.join(data_dir, 'roi_masks', r),\n",
    "            allow_pickle=True).item())\n",
    "\n",
    "    # Load the ROI brain surface maps\n",
    "    lh_challenge_roi_files = ['lh.prf-visualrois_challenge_space.npy',\n",
    "        'lh.floc-bodies_challenge_space.npy', 'lh.floc-faces_challenge_space.npy',\n",
    "        'lh.floc-places_challenge_space.npy', 'lh.floc-words_challenge_space.npy',\n",
    "        'lh.streams_challenge_space.npy']\n",
    "    rh_challenge_roi_files = ['rh.prf-visualrois_challenge_space.npy',\n",
    "        'rh.floc-bodies_challenge_space.npy', 'rh.floc-faces_challenge_space.npy',\n",
    "        'rh.floc-places_challenge_space.npy', 'rh.floc-words_challenge_space.npy',\n",
    "        'rh.streams_challenge_space.npy']\n",
    "    lh_challenge_rois = []\n",
    "    rh_challenge_rois = []\n",
    "    for r in range(len(lh_challenge_roi_files)):\n",
    "        lh_challenge_rois.append(np.load(os.path.join(data_dir, 'roi_masks',\n",
    "            lh_challenge_roi_files[r])))\n",
    "        rh_challenge_rois.append(np.load(os.path.join(data_dir, 'roi_masks',\n",
    "            rh_challenge_roi_files[r])))\n",
    "\n",
    "    # Select the correlation results vertices of each ROI\n",
    "    roi_names = []\n",
    "    lh_roi_correlation = []\n",
    "    rh_roi_correlation = []\n",
    "    for r1 in range(len(lh_challenge_rois)):\n",
    "        for r2 in roi_name_maps[r1].items():\n",
    "            if r2[0] != 0: # zeros indicate to vertices falling outside the ROI of interest\n",
    "                roi_names.append(r2[1])\n",
    "                lh_roi_idx = np.where(lh_challenge_rois[r1] == r2[0])[0]\n",
    "                rh_roi_idx = np.where(rh_challenge_rois[r1] == r2[0])[0]\n",
    "                lh_roi_correlation.append(lh_correlation[lh_roi_idx])\n",
    "                rh_roi_correlation.append(rh_correlation[rh_roi_idx])\n",
    "    roi_names.append('All vertices')\n",
    "    lh_roi_correlation.append(lh_correlation)\n",
    "    rh_roi_correlation.append(rh_correlation)\n",
    "\n",
    "    # Create the plot\n",
    "    lh_median_roi_correlation = [np.median(lh_roi_correlation[r])\n",
    "        for r in range(len(lh_roi_correlation))]\n",
    "    rh_median_roi_correlation = [np.median(rh_roi_correlation[r])\n",
    "        for r in range(len(rh_roi_correlation))]\n",
    "    plt.figure(figsize=(18,6))\n",
    "    x = np.arange(len(roi_names))\n",
    "    width = 0.30\n",
    "    plt.bar(x - width/2, lh_median_roi_correlation, width, label='Left Hemisphere')\n",
    "    plt.bar(x + width/2, rh_median_roi_correlation, width,\n",
    "        label='Right Hemishpere')\n",
    "    plt.xlim(left=min(x)-.5, right=max(x)+.5)\n",
    "    plt.ylim(bottom=0, top=1)\n",
    "    plt.xlabel('ROIs')\n",
    "    plt.xticks(ticks=x, labels=roi_names, rotation=60)\n",
    "    plt.ylabel('Median Pearson\\'s $r$')\n",
    "    plt.legend(frameon=True, loc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calulate_correlaction(lh_fmri_val, lh_fmri_val_pred, rh_fmri_val, rh_fmri_val_pred):\n",
    "    # Empty correlation array of shape: (LH vertices)\n",
    "    lh_correlation = np.zeros(lh_fmri_val_pred.shape[1])\n",
    "    # Correlate each predicted LH vertex with the corresponding ground truth vertex\n",
    "    for v in range(lh_fmri_val_pred.shape[1]):\n",
    "        lh_correlation[v] = corr(lh_fmri_val_pred[:,v], lh_fmri_val[:,v])[0]\n",
    "\n",
    "    # Empty correlation array of shape: (RH vertices)\n",
    "    rh_correlation = np.zeros(rh_fmri_val_pred.shape[1])\n",
    "    # Correlate each predicted RH vertex with the corresponding ground truth vertex\n",
    "    for v in range(rh_fmri_val_pred.shape[1]):\n",
    "        rh_correlation[v] = corr(rh_fmri_val_pred[:,v], rh_fmri_val[:,v])[0]\n",
    "    return lh_correlation, rh_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(lh_fmri_test_pred, rh_fmri_test_pred, subject_submission_dir):\n",
    "    lh_fmri_test_pred = lh_fmri_test_pred.astype(np.float32)\n",
    "    rh_fmri_test_pred = rh_fmri_test_pred.astype(np.float32)\n",
    "\n",
    "    np.save(os.path.join(subject_submission_dir, 'lh_pred_test.npy'), lh_fmri_test_pred)\n",
    "    np.save(os.path.join(subject_submission_dir, 'rh_pred_test.npy'), rh_fmri_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fmri data and image datasets per subject\n",
    "def load_FMRI_and_images(subj_dir, create_dataset_from_image_paths, batch_size):\n",
    "    train_img_dir  = os.path.join(subj_dir, 'training_split', 'training_images')\n",
    "    test_img_dir  = os.path.join(subj_dir, 'test_split', 'test_images')\n",
    "    train_img_list = os.listdir(train_img_dir)\n",
    "    # Create a dataset\n",
    "    split = 0.9\n",
    "    num_batches_train = int(len(train_img_list) * split // batch_size)\n",
    "    num_samples_train = int(num_batches_train * batch_size)\n",
    "    # Handle frmi files\n",
    "    fmri_dir = os.path.join(subj_dir, 'training_split', 'training_fmri')\n",
    "    lh_fmri = np.load(os.path.join(fmri_dir, 'lh_training_fmri.npy'))\n",
    "    rh_fmri = np.load(os.path.join(fmri_dir, 'rh_training_fmri.npy'))\n",
    "\n",
    "    print('LH training fMRI data shape:')\n",
    "    print(lh_fmri.shape)\n",
    "    print('(Training stimulus images × LH vertices)')\n",
    "\n",
    "    print('\\nRH training fMRI data shape:')\n",
    "    print(rh_fmri.shape)\n",
    "    print('(Training stimulus images × RH vertices)')\n",
    "    lh_fmri_train = lh_fmri[:num_samples_train]\n",
    "    lh_fmri_val = lh_fmri[num_samples_train:]\n",
    "    rh_fmri_train = rh_fmri[:num_samples_train]\n",
    "    rh_fmri_val = rh_fmri[num_samples_train:]\n",
    "\n",
    "    dataset = create_dataset_from_image_paths(train_img_dir, batch_size)\n",
    "    # create train and validation dataset from the training dataset (90% train, 10% validation)\n",
    "    train_dataset = dataset.take(num_batches_train)\n",
    "    val_dataset = dataset.skip(num_batches_train)\n",
    "\n",
    "    test_dataset = create_dataset_from_image_paths(test_img_dir, batch_size)\n",
    "\n",
    "    print('Training dataset size: ' + str(len(train_dataset)))\n",
    "    print('Validation dataset size: ' + str(len(val_dataset)))\n",
    "    print('Test dataset size: ' + str(len(test_dataset)) + '\\n')\n",
    "\n",
    "    return (train_dataset, val_dataset, test_dataset, lh_fmri_train, lh_fmri_val, rh_fmri_train, rh_fmri_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(base_model, readout_layer, lh_fmri_train, rh_fmri_train, lh_fmri_val, rh_fmri_val, train_dataset, val_dataset, test_dataset, batch_size):\n",
    "    \n",
    "    model = tf.keras.Model(inputs=base_model.input, outputs=base_model.get_layer(readout_layer).output)\n",
    "    # pca = PCA(n_components=100)\n",
    "    pca = IncrementalPCA(n_components=100, batch_size=batch_size)\n",
    "\n",
    "    # Fit PCA to batch of datastet\n",
    "    for batch in train_dataset:\n",
    "        # with HiddenPrints():\n",
    "        # Extract features\n",
    "        features = model.predict(batch)\n",
    "        # Flatten the features\n",
    "        features = features.reshape(features.shape[0], -1)\n",
    "        # Fit PCA to batch of features\n",
    "        pca.partial_fit(features)\n",
    "\n",
    "    # print('plot the explained variance')\n",
    "    # plt.plot(pca.explained_variance_ratio_)\n",
    "    # plt.show()\n",
    "    # print('plot the cumulative explained variance')\n",
    "    # plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    # plt.show()\n",
    "\n",
    "    def extract_features(dataset, model, pca):\n",
    "        features = []\n",
    "        for batch in dataset:\n",
    "            with HiddenPrints():\n",
    "                ft = model.predict(batch)\n",
    "                # Flatten the features\n",
    "                ft = ft.reshape(ft.shape[0], -1)\n",
    "                # Fit PCA to batch of features\n",
    "                ft = pca.transform(ft)\n",
    "            features.append(ft)\n",
    "        return np.vstack(features)\n",
    "\n",
    "    features_train = extract_features(train_dataset, model, pca)\n",
    "    features_val = extract_features(val_dataset, model, pca)\n",
    "    features_test = extract_features(test_dataset, model, pca)\n",
    "\n",
    "    del model, pca\n",
    "    # Fitting regression\n",
    "    reg_lh = LinearRegression().fit(features_train, lh_fmri_train)\n",
    "    reg_rh = LinearRegression().fit(features_train, rh_fmri_train)\n",
    "    # Use fitted linear regressions to predict the validation and test fMRI data\n",
    "    lh_fmri_val_pred = reg_lh.predict(features_val)\n",
    "    lh_fmri_test_pred = reg_lh.predict(features_test)\n",
    "    rh_fmri_val_pred = reg_rh.predict(features_val)\n",
    "    rh_fmri_test_pred = reg_rh.predict(features_test)\n",
    "    # Calculate correlation\n",
    "    lh_correlation, rh_correlation = calulate_correlaction(lh_fmri_val, lh_fmri_val_pred, rh_fmri_val, rh_fmri_val_pred)\n",
    "    return (lh_fmri_test_pred, rh_fmri_test_pred, lh_correlation, rh_correlation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify image preprocessing steps, model and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 -> rescaling -> normalization -> tf.math.truediv -> stem_conv_pad -> stem_conv -> stem_bn -> stem_activation -> block1a_dwconv -> block1a_bn -> block1a_activation -> block1a_se_squeeze -> block1a_se_reshape -> block1a_se_reduce -> block1a_se_expand -> block1a_se_excite -> block1a_project_conv -> block1a_project_bn -> block1b_dwconv -> block1b_bn -> block1b_activation -> block1b_se_squeeze -> block1b_se_reshape -> block1b_se_reduce -> block1b_se_expand -> block1b_se_excite -> block1b_project_conv -> block1b_project_bn -> block1b_drop -> block1b_add -> block2a_expand_conv -> block2a_expand_bn -> block2a_expand_activation -> block2a_dwconv_pad -> block2a_dwconv -> block2a_bn -> block2a_activation -> block2a_se_squeeze -> block2a_se_reshape -> block2a_se_reduce -> block2a_se_expand -> block2a_se_excite -> block2a_project_conv -> block2a_project_bn -> block2b_expand_conv -> block2b_expand_bn -> block2b_expand_activation -> block2b_dwconv -> block2b_bn -> block2b_activation -> block2b_se_squeeze -> block2b_se_reshape -> block2b_se_reduce -> block2b_se_expand -> block2b_se_excite -> block2b_project_conv -> block2b_project_bn -> block2b_drop -> block2b_add -> block2c_expand_conv -> block2c_expand_bn -> block2c_expand_activation -> block2c_dwconv -> block2c_bn -> block2c_activation -> block2c_se_squeeze -> block2c_se_reshape -> block2c_se_reduce -> block2c_se_expand -> block2c_se_excite -> block2c_project_conv -> block2c_project_bn -> block2c_drop -> block2c_add -> block3a_expand_conv -> block3a_expand_bn -> block3a_expand_activation -> block3a_dwconv_pad -> block3a_dwconv -> block3a_bn -> block3a_activation -> block3a_se_squeeze -> block3a_se_reshape -> block3a_se_reduce -> block3a_se_expand -> block3a_se_excite -> block3a_project_conv -> block3a_project_bn -> block3b_expand_conv -> block3b_expand_bn -> block3b_expand_activation -> block3b_dwconv -> block3b_bn -> block3b_activation -> block3b_se_squeeze -> block3b_se_reshape -> block3b_se_reduce -> block3b_se_expand -> block3b_se_excite -> block3b_project_conv -> block3b_project_bn -> block3b_drop -> block3b_add -> block3c_expand_conv -> block3c_expand_bn -> block3c_expand_activation -> block3c_dwconv -> block3c_bn -> block3c_activation -> block3c_se_squeeze -> block3c_se_reshape -> block3c_se_reduce -> block3c_se_expand -> block3c_se_excite -> block3c_project_conv -> block3c_project_bn -> block3c_drop -> block3c_add -> block4a_expand_conv -> block4a_expand_bn -> block4a_expand_activation -> block4a_dwconv_pad -> block4a_dwconv -> block4a_bn -> block4a_activation -> block4a_se_squeeze -> block4a_se_reshape -> block4a_se_reduce -> block4a_se_expand -> block4a_se_excite -> block4a_project_conv -> block4a_project_bn -> block4b_expand_conv -> block4b_expand_bn -> block4b_expand_activation -> block4b_dwconv -> block4b_bn -> block4b_activation -> block4b_se_squeeze -> block4b_se_reshape -> block4b_se_reduce -> block4b_se_expand -> block4b_se_excite -> block4b_project_conv -> block4b_project_bn -> block4b_drop -> block4b_add -> block4c_expand_conv -> block4c_expand_bn -> block4c_expand_activation -> block4c_dwconv -> block4c_bn -> block4c_activation -> block4c_se_squeeze -> block4c_se_reshape -> block4c_se_reduce -> block4c_se_expand -> block4c_se_excite -> block4c_project_conv -> block4c_project_bn -> block4c_drop -> block4c_add -> block4d_expand_conv -> block4d_expand_bn -> block4d_expand_activation -> block4d_dwconv -> block4d_bn -> block4d_activation -> block4d_se_squeeze -> block4d_se_reshape -> block4d_se_reduce -> block4d_se_expand -> block4d_se_excite -> block4d_project_conv -> block4d_project_bn -> block4d_drop -> block4d_add -> block4e_expand_conv -> block4e_expand_bn -> block4e_expand_activation -> block4e_dwconv -> block4e_bn -> block4e_activation -> block4e_se_squeeze -> block4e_se_reshape -> block4e_se_reduce -> block4e_se_expand -> block4e_se_excite -> block4e_project_conv -> block4e_project_bn -> block4e_drop -> block4e_add -> block5a_expand_conv -> block5a_expand_bn -> block5a_expand_activation -> block5a_dwconv -> block5a_bn -> block5a_activation -> block5a_se_squeeze -> block5a_se_reshape -> block5a_se_reduce -> block5a_se_expand -> block5a_se_excite -> block5a_project_conv -> block5a_project_bn -> block5b_expand_conv -> block5b_expand_bn -> block5b_expand_activation -> block5b_dwconv -> block5b_bn -> block5b_activation -> block5b_se_squeeze -> block5b_se_reshape -> block5b_se_reduce -> block5b_se_expand -> block5b_se_excite -> block5b_project_conv -> block5b_project_bn -> block5b_drop -> block5b_add -> block5c_expand_conv -> block5c_expand_bn -> block5c_expand_activation -> block5c_dwconv -> block5c_bn -> block5c_activation -> block5c_se_squeeze -> block5c_se_reshape -> block5c_se_reduce -> block5c_se_expand -> block5c_se_excite -> block5c_project_conv -> block5c_project_bn -> block5c_drop -> block5c_add -> block5d_expand_conv -> block5d_expand_bn -> block5d_expand_activation -> block5d_dwconv -> block5d_bn -> block5d_activation -> block5d_se_squeeze -> block5d_se_reshape -> block5d_se_reduce -> block5d_se_expand -> block5d_se_excite -> block5d_project_conv -> block5d_project_bn -> block5d_drop -> block5d_add -> block5e_expand_conv -> block5e_expand_bn -> block5e_expand_activation -> block5e_dwconv -> block5e_bn -> block5e_activation -> block5e_se_squeeze -> block5e_se_reshape -> block5e_se_reduce -> block5e_se_expand -> block5e_se_excite -> block5e_project_conv -> block5e_project_bn -> block5e_drop -> block5e_add -> block6a_expand_conv -> block6a_expand_bn -> block6a_expand_activation -> block6a_dwconv_pad -> block6a_dwconv -> block6a_bn -> block6a_activation -> block6a_se_squeeze -> block6a_se_reshape -> block6a_se_reduce -> block6a_se_expand -> block6a_se_excite -> block6a_project_conv -> block6a_project_bn -> block6b_expand_conv -> block6b_expand_bn -> block6b_expand_activation -> block6b_dwconv -> block6b_bn -> block6b_activation -> block6b_se_squeeze -> block6b_se_reshape -> block6b_se_reduce -> block6b_se_expand -> block6b_se_excite -> block6b_project_conv -> block6b_project_bn -> block6b_drop -> block6b_add -> block6c_expand_conv -> block6c_expand_bn -> block6c_expand_activation -> block6c_dwconv -> block6c_bn -> block6c_activation -> block6c_se_squeeze -> block6c_se_reshape -> block6c_se_reduce -> block6c_se_expand -> block6c_se_excite -> block6c_project_conv -> block6c_project_bn -> block6c_drop -> block6c_add -> block6d_expand_conv -> block6d_expand_bn -> block6d_expand_activation -> block6d_dwconv -> block6d_bn -> block6d_activation -> block6d_se_squeeze -> block6d_se_reshape -> block6d_se_reduce -> block6d_se_expand -> block6d_se_excite -> block6d_project_conv -> block6d_project_bn -> block6d_drop -> block6d_add -> block6e_expand_conv -> block6e_expand_bn -> block6e_expand_activation -> block6e_dwconv -> block6e_bn -> block6e_activation -> block6e_se_squeeze -> block6e_se_reshape -> block6e_se_reduce -> block6e_se_expand -> block6e_se_excite -> block6e_project_conv -> block6e_project_bn -> block6e_drop -> block6e_add -> block6f_expand_conv -> block6f_expand_bn -> block6f_expand_activation -> block6f_dwconv -> block6f_bn -> block6f_activation -> block6f_se_squeeze -> block6f_se_reshape -> block6f_se_reduce -> block6f_se_expand -> block6f_se_excite -> block6f_project_conv -> block6f_project_bn -> block6f_drop -> block6f_add -> block7a_expand_conv -> block7a_expand_bn -> block7a_expand_activation -> block7a_dwconv -> block7a_bn -> block7a_activation -> block7a_se_squeeze -> block7a_se_reshape -> block7a_se_reduce -> block7a_se_expand -> block7a_se_excite -> block7a_project_conv -> block7a_project_bn -> block7b_expand_conv -> block7b_expand_bn -> block7b_expand_activation -> block7b_dwconv -> block7b_bn -> block7b_activation -> block7b_se_squeeze -> block7b_se_reshape -> block7b_se_reduce -> block7b_se_expand -> block7b_se_excite -> block7b_project_conv -> block7b_project_bn -> block7b_drop -> block7b_add -> top_conv -> top_bn -> top_activation -> avg_pool -> top_dropout -> predictions\n"
     ]
    }
   ],
   "source": [
    "batch_size = 600\n",
    "def create_dataset_from_image_paths(image_dir, batch_size):\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(image_dir, image_size=(300, 300), labels=None, shuffle=False, batch_size=batch_size)\n",
    "    dataset = dataset.map(tf.keras.applications.efficientnet.preprocess_input)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Take models from here https://keras.io/api/applications/\n",
    "base_model = tf.keras.applications.EfficientNetB3(weights='imagenet')\n",
    "print(*(layer.name for layer in base_model.layers), sep=' -> ')\n",
    "\n",
    "# layers = ['block5d_bn', 'block5c_bn', 'block5b_bn', 'block5a_bn']\n",
    "layers = ['block4e_bn'] #, 'block3c_bn', 'block2c_bn', 'block1b_bn']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LH training fMRI data shape:\n",
      "(9841, 19004)\n",
      "(Training stimulus images × LH vertices)\n",
      "\n",
      "RH training fMRI data shape:\n",
      "(9841, 20544)\n",
      "(Training stimulus images × RH vertices)\n",
      "Found 9841 files belonging to 1 classes.\n",
      "Found 159 files belonging to 1 classes.\n",
      "Training dataset size: 14\n",
      "Validation dataset size: 3\n",
      "Test dataset size: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subj = 'subj01'\n",
    "subj_data_dir = os.path.join(data_dir, subj)\n",
    "subj_submission_dir = os.path.join(submission_dir, subj)\n",
    "train_dataset, val_dataset, test_dataset, lh_fmri_train, lh_fmri_val, rh_fmri_train, rh_fmri_val = load_FMRI_and_images(subj_data_dir, create_dataset_from_image_paths, batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readout layer: block4e_bn\n",
      "\n",
      "19/19 [==============================] - 6s 106ms/step\n",
      "19/19 [==============================] - 2s 86ms/step\n",
      "19/19 [==============================] - 2s 84ms/step\n",
      "19/19 [==============================] - 2s 83ms/step\n",
      "19/19 [==============================] - 2s 83ms/step\n",
      "19/19 [==============================] - 2s 84ms/step\n",
      "19/19 [==============================] - 2s 86ms/step\n",
      "19/19 [==============================] - 2s 83ms/step\n",
      "19/19 [==============================] - 2s 83ms/step\n",
      "19/19 [==============================] - 2s 83ms/step\n",
      "19/19 [==============================] - 2s 84ms/step\n"
     ]
    }
   ],
   "source": [
    "for readout_layer in layers:\n",
    "    print(f'Readout layer: {readout_layer}\\n')\n",
    "    lh_fmri_test_pred, rh_fmri_test_pred, lh_correlation, rh_correlation = run_pipeline(\n",
    "        base_model, readout_layer, \n",
    "        lh_fmri_train, rh_fmri_train, lh_fmri_val, rh_fmri_val, \n",
    "        train_dataset, val_dataset, test_dataset,\n",
    "        batch_size)\n",
    "    print('Left hemisphere median correlation: ', np.median(lh_correlation))\n",
    "    print('Right hemisphere median correlation: ', np.median(rh_correlation))\n",
    "    visualize_correlation(lh_correlation, rh_correlation, subj_data_dir)\n",
    "    save_predictions(lh_fmri_test_pred, rh_fmri_test_pred, subj_submission_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "365c028d1c840c93b0f470009ef966704a741407ca08d29f5bd0c0c6373757cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
