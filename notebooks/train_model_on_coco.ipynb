{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-datasets\n",
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COCO 2017 dataset with annotations\n",
    "dataset, info = tfds.load('coco/2017', with_info=True, data_dir='/notebooks/tensorflow_datasets')\n",
    "num_classes = 80 # number of classes in COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets_from_coco(dataset, transform_image, num_classes):\n",
    "\n",
    "    # Function to encode labels in multi-hot encoding\n",
    "    def encode_coco_categories(coco_categories, num_classes):\n",
    "        return tf.reduce_max(tf.one_hot(coco_categories, num_classes), axis=0)\n",
    "\n",
    "    # Function to set labels to zeros\n",
    "    def set_labels_as_zeros():\n",
    "        return tf.zeros(num_classes, tf.float32)\n",
    "\n",
    "    def preprocess(example, transform_image):\n",
    "        image = example['image']\n",
    "        image = transform_image(image)\n",
    "        coco_categories = example['objects']['label']\n",
    "\n",
    "        # Check if the image has no objects\n",
    "        is_empty = tf.equal(tf.size(coco_categories), 0)\n",
    "\n",
    "        # Use tf.cond to set labels to zeros if the image has no objects or to encode labels if the image has objects\n",
    "        labels = tf.cond(is_empty, set_labels_as_zeros, lambda: encode_coco_categories(coco_categories, num_classes))\n",
    "        return image, labels\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    train_ds = dataset['train'].map(lambda x: preprocess(x, transform_image)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = dataset['validation'].map(lambda x: preprocess(x, transform_image)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your own model (Alexnet example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alexnet specific preprocessing\n",
    "def transform_image(image):\n",
    "    image = tf.image.resize(image, (227, 227))\n",
    "    image = tf.cast(image, tf.float32) / 127.5 - 1.0\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    variance = [0.229, 0.224, 0.225]\n",
    "    normalization_layer = Normalization(mean=mean, variance=variance)\n",
    "    image = normalization_layer(image)\n",
    "    return image\n",
    "\n",
    "train_ds, val_ds = create_datasets_from_coco(dataset, transform_image, num_classes)\n",
    "\n",
    "input_shape = (227, 227, 3)\n",
    "\n",
    "model = Sequential()\n",
    "# Convolutional layers\n",
    "model.add(Conv2D(96, (11, 11), strides=(4, 4), activation=\"relu\", input_shape=input_shape, padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "model.add(Conv2D(256, (5, 5), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "model.add(Conv2D(384, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(384, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation=\"relu\", kernel_initializer=\"glorot_normal\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation=\"relu\", kernel_initializer=\"glorot_normal\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics='accuracy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or load pretrained archtecture and change the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vgg16 specific preprocessing\n",
    "def transform_image(image):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
    "    return image\n",
    "    \n",
    "train_ds, val_ds = create_datasets_from_coco(dataset, transform_image, num_classes)\n",
    "\n",
    "# Load the VGG16 model without the top layers\n",
    "base_model = tf.keras.applications.VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add top layers for multi-label classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(2048, activation='relu', name='dense_additional1')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation='relu', name='dense_additional2')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Print the layer names\n",
    "print(*(layer.name for layer in model.layers), sep=' -> ')\n",
    "\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "f1_score = tfa.metrics.F1Score(num_classes=num_classes, average='macro')\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimiser, loss='binary_crossentropy', metrics=[f1_score])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
    "model.save('model.h5')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history[f1_score.name])\n",
    "plt.plot(history.history[f'val_{f1_score.name}'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
