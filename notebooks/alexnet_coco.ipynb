{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load COCO 2017 dataset with annotations\n",
    "dataset, info = tfds.load('coco/2017', with_info=True, data_dir='/notebooks/tensorflow_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classes or categories you want to classify\n",
    "classes = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
    "    'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',\n",
    "    'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
    "    'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',\n",
    "    'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
    "    'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "num_classes = len(classes)\n",
    "def preprocess(example):\n",
    "    image = example['image']\n",
    "    image = tf.image.resize(image, (227, 227))\n",
    "    image = tf.cast(image, tf.float32) / 256\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    variance = [0.229, 0.224, 0.225]\n",
    "    normalization_layer = tf.keras.layers.experimental.preprocessing.Normalization(mean=mean, variance=variance)\n",
    "    image = normalization_layer(image)\n",
    "    \n",
    "    objects = example['objects']['label']\n",
    "    label = tf.reduce_max(tf.one_hot(objects, num_classes), axis=0)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = dataset['train'].map(preprocess).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = dataset['validation'].map(preprocess).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "# see a picture and its label\n",
    "for image, label in train_ds.take(1):\n",
    "    image_number = 8\n",
    "    plt.imshow(image[image_number])\n",
    "    plt.show()\n",
    "    print(label[image_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (227, 227, 3)\n",
    "\n",
    "model = Sequential()\n",
    "tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "# Convolutional layers\n",
    "model.add(Conv2D(96, (11, 11), strides=(4, 4), activation=\"relu\", input_shape=(227, 227, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "model.add(Conv2D(256, (5, 5), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "model.add(Conv2D(384, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(384, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
    "\n",
    "model.save('model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
