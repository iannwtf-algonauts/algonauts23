{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Torch pipeline\n",
    "Use a torch model as encoding model to predict brain data.\n",
    "First let's define an experiment name and some parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "experiment = 'torch_alexnet'\n",
    "batch_size = 300\n",
    "# Pick mps for Apple chip, cuda for nvidia & cpu otherwise\n",
    "device = 'mps'  # @param ['cpu', 'cuda'] {allow-input: true}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(device)\n",
    "\n",
    "# Configure folders\n",
    "challenge_data_dir = '../data/algonauts_2023_challenge_data'\n",
    "exp_output_dir = f'../data/out/{experiment}'\n",
    "\n",
    "# Get feature extractor\n",
    "from src.algonauts.feature_extractors.TorchFeatureExtractor import TorchFeatureExtractor\n",
    "random_seed = 5\n",
    "feature_extractor = TorchFeatureExtractor(batch_size, random_seed, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load model\n",
    "Define a function to load and return the model, printing its layers.\n",
    "Due to memory constraints, we will delete the model from memory in each loop. Here we first load it, print its\n",
    "nodes and delete it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "    model.to(device)  # send the model to the chosen device ('cpu' or 'cuda')\n",
    "    model.eval()  # set the model to evaluation mode, since you are not training it\n",
    "    return model\n",
    "\n",
    "\n",
    "model = load_model()\n",
    "train_nodes, _ = get_graph_node_names(model)\n",
    "print(train_nodes)\n",
    "del model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Select layers and subjects\n",
    "Now let's define which layer(s) we will pick from, and which subject(s) to process"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "layers = ['features.12']\n",
    "subjects = [1, 2, 3, 4, 5, 6, 7, 8]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.algonauts.evaluators import Correlations\n",
    "from src.algonauts.encoders import LinearEncoder\n",
    "from src.algonauts.data_processors.NSDDataset import NSDDataset\n",
    "\n",
    "for layer_name in layers:\n",
    "    print(f'Running for layer {layer_name}')\n",
    "    for subj in subjects:\n",
    "        print(f'Running for subject {subj}')\n",
    "\n",
    "        # Set data directories based on parameters\n",
    "        output_dir = f'{exp_output_dir}/{layer_name}'\n",
    "        dataset = NSDDataset(challenge_data_dir, output_dir, subj)\n",
    "\n",
    "        # Load model for the iteration\n",
    "        model = load_model()\n",
    "\n",
    "        # Extract features from the layer\n",
    "        train_features, val_features, test_features = feature_extractor.extract_all_features(dataset, model, layer_name)\n",
    "\n",
    "        # Delete model to free up memory\n",
    "        del model\n",
    "\n",
    "        # Apply PCA and fit linear encoder to get fMRI predictions\n",
    "        lh_fmri_val_pred, rh_fmri_val_pred = LinearEncoder.predict(dataset, train_features, val_features, test_features)\n",
    "        # Calculate correlations for each hemisphere\n",
    "        lh_correlation = Correlations.calculate_correlation(lh_fmri_val_pred, dataset.lh_fmri_val)\n",
    "        rh_correlation = Correlations.calculate_correlation(rh_fmri_val_pred, dataset.rh_fmri_val)\n",
    "        Correlations.plot_and_write_correlations(dataset, lh_correlation, rh_correlation, exp_output_dir, layer_name, subj)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
